{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RblsFDzQ8zVz",
        "outputId": "b6878c8d-1105-4dc5-c6f9-2447bf61a6b7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.33.2-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.2-py3-none-any.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.17.2 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import GPT2Tokenizer, GPT2Model\n",
        "import torch"
      ],
      "metadata": {
        "id": "5e02MpOn8qFi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKQRc0Qh9GQM",
        "outputId": "69e6899e-3b90-457a-9806-3caf02c54ae0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/text_classification/word_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1p5eW9TL9Tlx",
        "outputId": "1adaec22-5597-43df-abb1-d27626a6046e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/text_classification/word_vectors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read excel file\n",
        "df = pd.read_excel('./data.xlsx')\n",
        "\n",
        "# Initialize GPT2 tokenizer and model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "model = GPT2Model.from_pretrained('gpt2')\n",
        "\n",
        "# Get the maximum length of the tensors\n",
        "max_length = 0\n",
        "for index, row in df.iterrows():\n",
        "    text = row['review']\n",
        "    inputs = tokenizer(text, return_tensors='pt')\n",
        "    max_length = max(max_length, inputs.input_ids.shape[1])\n",
        "\n",
        "# Create a list to store all the padded tensors\n",
        "all_vectors = []\n",
        "\n",
        "# For each row in the DataFrame\n",
        "for index, row in df.iterrows():\n",
        "    text = row['review']\n",
        "    inputs = tokenizer(text, return_tensors='pt')\n",
        "\n",
        "    # Pad the input tensor to the maximum length\n",
        "    padded_inputs = torch.nn.functional.pad(inputs.input_ids, (0, max_length - inputs.input_ids.shape[1]))\n",
        "\n",
        "    # Pass the padded input through the model and get the last hidden state\n",
        "    outputs = model(input_ids=padded_inputs)\n",
        "    last_hidden_states = outputs.last_hidden_state\n",
        "\n",
        "    # Append the tensor to the list\n",
        "    all_vectors.append(last_hidden_states)\n",
        "\n",
        "# Concatenate the tensors along dimension 0\n",
        "all_vectors_tensor = torch.cat(all_vectors, dim=0)\n",
        "\n",
        "# Save to file\n",
        "torch.save(all_vectors_tensor, 'gpt2_vectors.pt')"
      ],
      "metadata": {
        "id": "jAUdmLmX-bYw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get a word vector\n",
        "word = \"宗教\"\n",
        "encoded_input = tokenizer.encode(word, return_tensors='pt')\n",
        "with torch.no_grad():\n",
        "    outputs = model(encoded_input)\n",
        "    last_hidden_state = outputs.last_hidden_state\n",
        "word_vector = last_hidden_state[0, 0, :]"
      ],
      "metadata": {
        "id": "vSlXYmf0_hZ_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Psb2U31T_mVr",
        "outputId": "c07ba113-fb7a-44c9-9a42-6650dc6e1f12"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.9958e-01, -6.1397e-02, -3.9569e-01,  8.8818e-03,  5.1586e-02,\n",
            "        -2.4651e-01,  3.8516e+00, -6.1524e-02, -2.2814e-01,  5.6127e-02,\n",
            "         4.2728e-01,  1.3186e-01,  1.0884e-01,  7.4197e-02, -2.9171e-01,\n",
            "         2.3068e-02,  3.1887e-03,  4.3155e-02, -6.3804e-02, -5.3721e-01,\n",
            "         1.1262e-01, -9.4910e-02, -2.1613e-01,  6.3404e-02,  5.5840e-02,\n",
            "         1.4192e-01, -1.6311e-01, -2.4839e-01, -8.7441e-02, -3.7314e-01,\n",
            "         2.9608e-02,  9.4477e-04, -8.7810e-02, -4.5631e-01, -8.8451e-02,\n",
            "         3.4351e-01,  2.1863e+01,  7.8878e-02,  8.2113e-02, -6.6090e-02,\n",
            "         1.5352e-02, -8.6923e-02,  5.9910e-02, -3.3587e-01, -5.5899e-02,\n",
            "         2.0056e-01, -1.7704e-01,  2.3824e-02,  6.1148e-02, -2.5813e-01,\n",
            "        -2.5291e-02,  7.7428e-02,  1.8166e-02, -7.5684e-02,  1.0221e-01,\n",
            "         1.9594e-01,  1.1243e-01, -1.2608e-01, -1.4457e-01, -6.6094e-02,\n",
            "        -6.1421e-02, -7.1418e-02, -8.3673e-02, -7.1453e-02, -1.0403e+00,\n",
            "        -1.4443e-01, -6.0125e-02, -3.6301e-02,  1.4528e-01, -1.8504e-01,\n",
            "        -1.5087e-01, -1.2577e-01, -1.8831e-01, -9.8201e-02, -6.8350e-02,\n",
            "        -4.3953e-01, -4.3343e-01, -1.5453e+00,  4.0850e-01, -2.5562e-01,\n",
            "        -5.3005e-01, -2.0515e-01,  5.6111e-02, -1.7257e-01, -3.3888e-02,\n",
            "         8.3546e-02, -2.3931e-01, -9.9034e-01, -1.5606e-01, -1.0800e-01,\n",
            "        -1.9302e-01, -2.3250e-01, -3.9579e-01, -1.3867e-01, -2.2467e-01,\n",
            "        -1.1378e-01, -2.7768e-01,  2.2370e-02,  8.6183e-02, -9.0021e-03,\n",
            "        -1.9861e-01,  1.0650e-01,  5.9289e-01,  1.7817e-01, -1.1436e-01,\n",
            "        -6.0914e-02, -7.0101e-02,  6.7247e+00, -1.1733e-01, -1.4730e-01,\n",
            "        -3.0112e-02,  7.7492e-03, -2.0632e-01,  1.6539e-01, -1.1979e-01,\n",
            "         1.3604e-01,  3.0870e-01,  4.6731e-02,  7.8628e-02, -1.7856e-01,\n",
            "        -2.4526e-01,  3.3586e-03, -2.1343e-01, -3.3500e-02, -3.1889e-02,\n",
            "        -6.0269e-02, -5.0190e-02,  3.5978e-02, -5.8438e-01, -7.7319e-02,\n",
            "         1.0554e-01,  4.3629e-02,  1.3359e-01, -1.2348e-01,  4.6392e-02,\n",
            "        -5.5715e-02,  1.7583e-02, -7.0445e-02,  5.9277e-01,  1.2411e-01,\n",
            "         4.9654e-02,  1.3374e-01, -1.1491e+00, -5.9896e-02, -4.7221e-02,\n",
            "         3.3151e-02, -1.7599e-02,  8.0363e-02, -6.8107e-02, -8.4074e-02,\n",
            "        -2.3494e-01, -1.7665e-01, -1.7746e-01,  9.9728e-03, -9.5023e-02,\n",
            "         3.5668e-02,  2.5114e-03, -6.6071e-02,  1.4188e-02, -6.6001e-02,\n",
            "         2.2889e-01, -9.5233e-02, -4.8711e-02, -9.3699e-02, -2.0575e-01,\n",
            "        -9.7486e-02,  1.1097e-01, -8.1143e-02, -7.6360e-02, -2.4796e-01,\n",
            "        -1.2410e-01, -1.0075e-01, -2.9437e-02,  5.7544e-02, -1.0812e-01,\n",
            "         7.0980e-02,  5.3800e-02, -2.8212e-01, -9.9195e-02, -7.6235e-02,\n",
            "        -1.8705e-01,  3.3958e-02,  1.4328e-02, -2.5904e-01, -9.0085e-02,\n",
            "        -1.9750e-01,  5.6449e-02, -7.2518e-02, -1.7254e-02,  3.3344e-02,\n",
            "        -2.4496e-01, -1.3823e-01, -2.0565e-01, -3.5257e-02, -6.0171e-02,\n",
            "        -1.2294e-01,  1.2930e-02, -1.3484e-01, -8.3579e-02,  1.5468e-02,\n",
            "         1.2221e-02,  1.2268e-02,  3.5914e-02, -9.4344e-02, -2.6826e-02,\n",
            "        -8.6843e-02, -3.2906e-01, -2.2580e-01,  9.1923e-03,  3.8264e-02,\n",
            "         1.8674e-02,  1.8557e-01, -5.0608e-02,  8.4873e-02, -5.0383e-02,\n",
            "        -8.6818e-02, -8.7103e-02, -2.3899e-01, -4.2730e-02, -2.7023e-02,\n",
            "        -6.0974e-02, -1.5758e-01, -1.3695e-01, -1.4495e-01,  2.1130e-01,\n",
            "        -1.2056e-01, -4.5484e-02, -7.9693e-02,  2.2517e-01, -6.2198e-02,\n",
            "         1.0132e-01,  1.5569e-01,  9.3336e-01, -4.5009e-02, -1.8964e-01,\n",
            "        -2.9194e-01, -1.2821e-01, -6.1000e-02, -5.4678e-02,  9.1571e-02,\n",
            "        -8.4197e-02, -1.1774e-01,  6.6302e-02, -1.2136e-01,  5.4739e-02,\n",
            "         8.9761e-02, -2.2608e-01,  8.4577e-02,  7.5697e-02, -3.3902e-01,\n",
            "        -5.0271e-01, -2.8342e-01,  1.6641e-01,  4.6396e-02, -7.1711e-02,\n",
            "         7.8067e-02,  1.3135e-01,  1.4656e-01,  4.1858e-03,  2.4328e-02,\n",
            "         9.6766e-02, -1.9846e-01, -1.1508e-02,  7.6016e-02, -4.0056e-02,\n",
            "        -1.6286e-01, -9.6883e-01, -2.3914e-01, -1.9374e-01,  3.9020e-02,\n",
            "         1.1587e-01,  3.7459e-01, -1.7696e-01,  5.7372e-02,  1.4528e-02,\n",
            "        -1.7471e-01,  5.0420e-02, -1.2529e-01, -2.7973e-01, -4.5354e-02,\n",
            "        -1.2136e-01, -7.9671e-03,  2.4253e-01,  1.1485e-02,  1.2708e-01,\n",
            "        -3.0906e-01, -8.6499e-02, -2.4845e-01, -6.2292e-02,  2.7804e-01,\n",
            "        -6.9611e-02, -1.4522e-01,  7.8556e-02,  6.7746e-02,  1.6650e-01,\n",
            "        -2.3900e-01, -1.1657e-02, -2.3950e-01,  5.4550e-02,  8.7476e-02,\n",
            "        -2.7722e-02,  1.9700e-01, -1.5630e-02, -4.1058e-02, -2.7198e-01,\n",
            "        -2.0258e-02,  1.2350e-02, -2.1892e-01, -2.5669e-02, -1.4074e-01,\n",
            "         5.8889e-02,  6.5856e-01, -3.7385e-02, -4.6744e-02,  7.2100e+00,\n",
            "        -3.3996e-02, -6.8552e-02,  5.4143e-02, -2.1011e-01,  4.9808e-02,\n",
            "        -9.0143e-01, -3.3375e-01, -2.4552e-01, -2.5398e-01,  1.1040e-01,\n",
            "        -4.8785e-02, -3.9634e-01, -2.4442e-02, -1.9846e-01, -2.9632e-01,\n",
            "        -2.5946e-01, -1.2981e-01,  1.2711e-02, -2.2061e-01,  1.4888e-01,\n",
            "        -1.3464e-01,  6.5361e-02, -5.7841e-02, -1.1361e-01, -3.0468e-01,\n",
            "         4.8089e-02,  4.5423e-02, -2.4816e-01, -1.4450e-01, -1.2186e-01,\n",
            "         1.2223e-01, -1.8097e-02, -3.2499e-01, -6.5555e-03,  4.3690e-02,\n",
            "        -2.0300e-01,  2.7137e-02, -7.0845e-03, -2.6304e-01, -1.5722e-01,\n",
            "         7.6320e-02, -4.0233e-01, -4.8423e-02, -9.2678e-02, -1.4015e-01,\n",
            "        -1.8592e-01, -1.3856e-01, -4.7426e-01, -2.6542e-01, -4.1302e-03,\n",
            "         3.1629e-01, -9.5223e-02, -3.6964e-03, -3.4877e-02,  3.2718e-02,\n",
            "         1.0647e-01, -3.2286e-02, -3.5042e-02, -7.1269e-01, -6.2205e+00,\n",
            "        -7.2806e-02, -1.3054e-01, -3.9562e-01, -6.5497e-01,  3.7353e-02,\n",
            "         3.5779e-03, -6.7616e-02, -4.9258e-02, -5.2501e-02, -3.1471e-01,\n",
            "         1.3077e-01,  3.0419e-02, -1.2933e-01,  5.3551e-02, -4.1775e-01,\n",
            "         7.6972e-02,  4.7127e-02, -2.9705e-02, -4.9379e-01, -8.3824e-03,\n",
            "        -4.1105e-02, -4.8924e-01, -3.7103e-02,  1.1504e-01, -4.4021e-02,\n",
            "        -8.8672e-02, -1.3509e-01, -6.3773e-02, -7.8078e-02, -1.4253e-02,\n",
            "         9.1850e-02,  4.8209e-05, -9.4407e-02, -1.3796e+00,  3.9650e-02,\n",
            "        -1.0779e-01, -6.8312e-02, -1.2183e-01, -2.7501e-01, -3.9892e-01,\n",
            "        -2.4541e-01, -6.1335e-02, -3.8299e-01, -3.0798e-01, -8.8261e-03,\n",
            "        -3.7835e-01, -1.7323e-02,  4.5373e-03, -5.5874e-02, -1.0304e-01,\n",
            "         4.6982e-02, -9.1814e-02, -1.7354e-01, -1.1372e-01, -2.8188e-01,\n",
            "         3.5230e+01,  3.1968e-02, -1.5944e-01, -1.7915e-01, -1.3201e-01,\n",
            "         4.7921e-03, -2.3466e-01, -4.0042e-03, -2.3137e-01,  3.9896e-01,\n",
            "        -1.4444e-01, -1.0418e-01,  6.0005e+00, -5.0793e-02,  6.1844e-02,\n",
            "        -9.8176e-02, -1.8131e-01,  1.6940e+00, -2.6782e-02,  1.0196e-01,\n",
            "        -1.5568e-01, -3.4473e-02,  1.0626e-02, -4.0360e-01,  1.8376e-03,\n",
            "        -3.1919e-01, -1.2458e-01, -1.1828e-01, -4.5184e-02, -6.6841e-02,\n",
            "         7.0239e-02, -8.4558e-02,  1.1652e-01, -2.2526e-01, -1.1533e-01,\n",
            "        -2.5264e-02,  3.4119e-03, -1.8522e-01, -1.9118e-01, -2.4193e-03,\n",
            "        -1.2530e-01,  7.5578e-02, -1.4702e-01, -2.1300e-01,  9.5893e-02,\n",
            "        -2.6030e-01, -1.3364e-01, -1.7649e-03, -2.1089e-01, -9.7010e-01,\n",
            "        -8.5394e-01,  6.6931e-01, -1.9017e-01, -1.9413e-01, -7.7413e-02,\n",
            "        -2.4313e-01, -4.2865e-02, -1.4795e-01, -1.2579e-01, -1.2282e-01,\n",
            "        -2.0087e-02, -2.1893e-01, -1.9847e-01, -6.3254e-02, -2.8549e-01,\n",
            "         1.3985e-01,  5.4887e+01, -4.0563e-01,  8.6394e-04, -6.3291e-02,\n",
            "        -3.6697e-01, -6.8920e-02, -1.9513e-01, -5.0341e-01, -2.8573e-01,\n",
            "         6.2907e-02,  3.9915e-02,  8.8740e-02, -1.7132e-01,  7.5036e-02,\n",
            "        -1.2567e-01, -6.7529e-02,  4.0405e-01, -1.4097e-01,  8.4944e-02,\n",
            "        -1.0422e-01, -6.1451e-02, -1.1837e-01, -6.8610e-02, -1.7719e-01,\n",
            "        -1.4758e-01, -2.1060e-01,  6.4546e-02, -1.8836e-01, -1.6873e-01,\n",
            "        -3.6130e-01, -5.7822e-01,  4.1166e-02, -2.8178e-01, -2.3799e-02,\n",
            "        -4.6984e-02, -4.9187e-02, -1.3794e-01, -1.8399e-01, -3.4752e-01,\n",
            "         1.6822e-02,  8.1618e-02, -4.5002e-01, -3.9314e-03, -1.2626e-01,\n",
            "         2.6078e-01, -1.0789e-01, -1.3041e-01, -4.3199e-01, -2.0127e-01,\n",
            "        -2.2049e-01, -5.4236e-02, -1.3677e-01,  8.1124e-02, -3.0357e-01,\n",
            "        -6.7461e-03, -3.3187e-02, -1.0832e-01, -3.1520e-01, -3.7968e-01,\n",
            "        -7.3626e-03,  3.5866e-02,  6.4690e-02, -2.0443e-01, -1.8858e-01,\n",
            "        -3.3462e-01, -9.0746e-02, -9.1724e-02,  2.4452e-02, -9.3884e-02,\n",
            "         4.4926e-02,  4.0635e-01, -4.3916e-01,  1.3295e-01,  1.5983e-03,\n",
            "        -1.4869e-01,  4.2815e-02, -2.4556e-02, -2.9118e-01, -1.4670e-01,\n",
            "        -2.8850e-02, -1.2550e-01, -3.5754e-03, -2.5571e-01,  6.0418e-02,\n",
            "        -1.4450e-01,  3.1791e-02, -1.1779e-01, -2.4733e-02, -5.7457e-02,\n",
            "        -9.0394e-02, -4.1890e-02, -2.1636e-01, -1.9464e-01, -5.0233e-02,\n",
            "         5.0197e-02,  1.6926e-02, -8.8340e-02, -9.9953e-02,  2.8457e-02,\n",
            "         2.5614e-01, -7.4532e-02,  3.9085e-03, -1.9094e-01, -8.2734e-02,\n",
            "         4.5782e-02, -1.0370e-01, -2.0607e-01, -4.2976e-02, -4.2248e-02,\n",
            "         1.3874e-02, -1.4658e-01, -9.8712e-02, -5.6216e-01, -6.0325e-02,\n",
            "        -3.1688e-01, -2.1719e-01,  3.6758e-02,  2.1166e-02, -2.6759e-01,\n",
            "        -1.3562e-01,  1.2967e-01, -9.9047e-02, -3.9662e-01, -9.9461e-02,\n",
            "        -1.0647e-01,  9.7417e-02,  1.6135e-02, -6.0986e-02,  4.2329e-02,\n",
            "        -6.3966e-02, -9.5920e-02,  4.9319e-01, -8.1095e-02, -2.4394e-01,\n",
            "        -3.0776e-03, -2.0272e-01,  3.3550e-02, -1.5811e-01,  6.4731e-02,\n",
            "        -1.6997e-01, -5.0910e-01,  4.5540e-02, -1.3000e-01,  4.4797e-02,\n",
            "        -3.8439e-01, -1.3165e-01, -2.1346e-01, -5.8619e-01, -1.6404e-01,\n",
            "         1.2990e-01, -3.5911e-01, -1.4024e-01,  5.1887e-02,  2.3694e-01,\n",
            "        -6.8236e-02,  1.7514e-01, -2.2062e-03, -1.1053e-02,  4.8898e-02,\n",
            "        -8.4224e-02,  1.1263e-01, -5.0261e-02, -5.0622e-02,  2.1847e-01,\n",
            "        -3.8211e-02, -7.1374e-02, -1.3252e-01,  2.0942e-03,  9.5281e-04,\n",
            "         3.3390e-01, -2.2388e-01, -1.6172e-01,  3.3699e-01, -1.8929e-01,\n",
            "         3.3310e-01, -1.4538e-01, -1.3213e-01,  8.0950e-02, -6.0606e-01,\n",
            "         8.5399e-02, -3.8821e-02, -1.9482e-01, -2.2766e-01, -8.6936e-01,\n",
            "        -1.4133e-01, -1.7813e-03, -1.9946e-01,  2.4717e-02, -1.1353e-01,\n",
            "        -1.5752e-01, -1.7281e-01, -1.1782e-01,  6.4242e-02, -4.7773e-02,\n",
            "        -6.5976e-02, -4.9553e-03, -1.9678e-02,  9.5081e-03,  8.4456e-03,\n",
            "         4.4664e-02, -9.0098e-02, -1.1126e-01, -3.8693e-02, -7.8366e-04,\n",
            "        -5.9727e-02, -1.0941e-01,  1.5140e-01, -1.0784e+01, -1.2543e-01,\n",
            "        -2.5289e-01, -1.1908e-01, -3.8074e-01, -9.3009e-02, -1.9274e-01,\n",
            "        -9.8657e-02, -6.7278e-02, -1.4495e-01, -2.3499e-01, -7.3146e-02,\n",
            "        -2.2620e-01, -2.2869e-01, -2.9858e-01, -1.4729e-01, -9.6683e-02,\n",
            "         1.2517e-02, -1.6328e-01, -1.6082e-01, -3.9902e-02,  4.6667e-01,\n",
            "         1.2664e-02, -6.8814e-02, -1.8427e-01, -4.8873e-02,  2.5375e-03,\n",
            "        -3.3749e-02, -4.2462e-02, -1.8596e-01,  5.5874e-02, -1.0581e-02,\n",
            "         3.7194e-02,  9.4072e-02, -2.3693e-02, -2.0152e-01, -6.2768e-02,\n",
            "        -2.0293e-01, -1.7558e-01, -1.3966e-01, -1.2499e-01, -2.2218e-01,\n",
            "        -5.2130e-01, -5.7335e-03,  6.2475e-02, -7.8111e-02,  5.0760e-02,\n",
            "        -1.6456e-02, -1.9211e-01, -1.1798e-02, -2.5287e-01,  1.1675e-01,\n",
            "         1.1084e-01, -4.9462e-02,  4.4599e-02, -1.0877e-01,  4.2420e-01,\n",
            "        -2.5318e-01,  1.1424e-01, -4.5235e-01, -5.6025e-02, -1.3605e-03,\n",
            "         6.7148e-02, -8.4633e-02,  1.8451e-02])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.hidden_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXtTnqZf_-8v",
        "outputId": "d4be7d87-562e-4334-a1d2-ea8b1555b529"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}