{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25773,"status":"ok","timestamp":1697892793165,"user":{"displayName":"Ruoheng Du","userId":"08748997774430241707"},"user_tz":-480},"id":"RblsFDzQ8zVz","outputId":"0d3b1b7d-ecc8-4106-85a0-a1666969e105"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers<0.15,>=0.14 (from transformers)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n","Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.1\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19758,"status":"ok","timestamp":1697892865067,"user":{"displayName":"Ruoheng Du","userId":"08748997774430241707"},"user_tz":-480},"id":"sKQRc0Qh9GQM","outputId":"f7cbb582-eab7-4aa9-c56e-b37c49a92cee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":456,"status":"ok","timestamp":1697892865516,"user":{"displayName":"Ruoheng Du","userId":"08748997774430241707"},"user_tz":-480},"id":"1p5eW9TL9Tlx","outputId":"bfb27614-22c2-4887-becd-cb2720c4ba1b"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/text_classification/dot/word2vec-gpt\n"]}],"source":["cd /content/drive/MyDrive/text_classification/dot/word2vec-gpt"]},{"cell_type":"code","source":["import pandas as pd\n","from transformers import GPT2Tokenizer, GPT2Model\n","import torch\n","import numpy as np\n","import jieba"],"metadata":{"id":"AdTWEmdybP19","executionInfo":{"status":"ok","timestamp":1697894959519,"user_tz":-480,"elapsed":5,"user":{"displayName":"Ruoheng Du","userId":"08748997774430241707"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["## gpt ##\n","# Read the Excel file\n","data = pd.read_excel('./data.xlsx')\n","sentences = data['review'].tolist()\n","\n","def txt_cut(s):\n","    res = [w for w in jieba.lcut(s) if w.strip()]\n","    return \" \".join(res)\n","\n","# 对文本进行分词\n","tokenized_text = []\n","for i in sentences:\n","    new = txt_cut(i).split(' ')\n","    tokenized_text.extend(new)\n","\n","# Initialize GPT-2 tokenizer and model\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","model = GPT2Model.from_pretrained('gpt2')\n","\n","# Create an empty list to store word vectors\n","word_vectors = []\n","\n","# Iterate through each row in the list\n","for word in tokenized_text:\n","\n","    # Encode the word with the tokenizer\n","    inputs = tokenizer(word, return_tensors='pt')\n","\n","    # Get the model's output for the word\n","    outputs = model(**inputs)\n","    last_hidden_state = outputs.last_hidden_state\n","\n","    # Append the word vector to the list\n","    word_vector = last_hidden_state[0, 0, :]\n","\n","    word_vectors.append((word, word_vector))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GGxQSqbOZ4o-","executionInfo":{"status":"ok","timestamp":1697895140508,"user_tz":-480,"elapsed":13185,"user":{"displayName":"Ruoheng Du","userId":"08748997774430241707"}},"outputId":"7c4431dd-389e-4a9d-92c2-a61e00dbb3ca"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["Building prefix dict from the default dictionary ...\n","DEBUG:jieba:Building prefix dict from the default dictionary ...\n","Dumping model to file cache /tmp/jieba.cache\n","DEBUG:jieba:Dumping model to file cache /tmp/jieba.cache\n","Loading model cost 4.227 seconds.\n","DEBUG:jieba:Loading model cost 4.227 seconds.\n","Prefix dict has been built successfully.\n","DEBUG:jieba:Prefix dict has been built successfully.\n"]}]},{"cell_type":"code","source":["# for word_vector in enumerate(word_vectors):\n","#     print(f\"Word: {word_vector[1][0]}, Word Vector: {word_vector[1][1]}\")"],"metadata":{"id":"5Mk4wy9Rcru6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from gensim.models import Word2Vec\n","import jieba"],"metadata":{"id":"vavWhbRwTS0X","executionInfo":{"status":"ok","timestamp":1697895172241,"user_tz":-480,"elapsed":2252,"user":{"displayName":"Ruoheng Du","userId":"08748997774430241707"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["## word2vec ##\n","\n","# 初始化Word2Vec模型\n","model_w = Word2Vec(vector_size=100, window=5, min_count=1)\n","\n","# 构建词汇表\n","model_w.build_vocab([tokenized_text])\n","\n","# 训练模型\n","model_w.train([tokenized_text], total_examples=model_w.corpus_count, epochs=model_w.epochs)\n","\n","# 创建一个空的DataFrame来保存词汇和对应的词向量\n","word_vector_df = pd.DataFrame()\n","\n","for wd in model_w.wv.index_to_key:\n","    # 将词向量转化为Series，然后添加到DataFrame中\n","    word_vector_series = pd.Series([wd] + list(model_w.wv[wd]))\n","    word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IgxWetVfTV0H","executionInfo":{"status":"ok","timestamp":1697895177294,"user_tz":-480,"elapsed":1105,"user":{"displayName":"Ruoheng Du","userId":"08748997774430241707"}},"outputId":"f3eb6298-8d25-45d9-ffd7-e0c13c4c5a23"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-23-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n"]}]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":282,"status":"ok","timestamp":1697895992266,"user":{"displayName":"Ruoheng Du","userId":"08748997774430241707"},"user_tz":-480},"id":"vSlXYmf0_hZ_"},"outputs":[],"source":["new_word_vectors = []\n","\n","for word_vector in enumerate(word_vectors):\n","    word_vector_g = word_vector[1][1].detach().numpy()\n","    word_vector_g = word_vector_g.reshape(-1, 1)\n","\n","    ## word2vec\n","    word_vector_w = model_w.wv[word_vector[1][0]]\n","    word_vector_w = word_vector_w.reshape(-1, 1)\n","\n","    ## 新词向量\n","    new_word_vector = np.multiply(word_vector_g, word_vector_w.T)\n","    new_word_vectors.append((word, new_word_vector))"]},{"cell_type":"code","source":["# 指定保存文件路径\n","save_path = 'new_word_vectors.txt'\n","\n","# 保存单词和新词向量到文件\n","with open(save_path, 'w') as f:\n","    for word, word_vector in new_word_vectors:\n","        word_vector_str = ','.join(map(str, word_vector))\n","        line = f\"{word}: {word_vector_str}\\n\"\n","        f.write(line)"],"metadata":{"id":"mJA2DyA7fNls","executionInfo":{"status":"ok","timestamp":1697896085743,"user_tz":-480,"elapsed":31588,"user":{"displayName":"Ruoheng Du","userId":"08748997774430241707"}}},"execution_count":43,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPyAMQ8uKPD25ZHkb/p0qzF"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}