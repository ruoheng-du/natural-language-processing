{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMjFMFEZdjZmjLYvpdPXc4c"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-S2Z0pErjOMN","executionInfo":{"status":"ok","timestamp":1697897226612,"user_tz":-480,"elapsed":15081,"user":{"displayName":"Ruoheng Du","userId":"08748997774430241707"}},"outputId":"eae55e37-38e1-4b72-ffbd-e9c3f5a1c9de"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers<0.15,>=0.14 (from transformers)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m124.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n","Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.1\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zEQDJmenj6qX","executionInfo":{"status":"ok","timestamp":1697897257327,"user_tz":-480,"elapsed":17386,"user":{"displayName":"Ruoheng Du","userId":"08748997774430241707"}},"outputId":"d02df465-7e16-4fa5-9b7d-e110260e117f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive/text_classification/dot/word2vec-bert"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v66c_igYj8tp","executionInfo":{"status":"ok","timestamp":1697897297009,"user_tz":-480,"elapsed":5,"user":{"displayName":"Ruoheng Du","userId":"08748997774430241707"}},"outputId":"f8c59a8c-176b-42da-f6dd-e1765ed51605"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/text_classification/dot/word2vec-bert\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from transformers import BertModel, BertTokenizer\n","import numpy as np\n","import torch\n","import jieba"],"metadata":{"id":"-kuYNP1Qj4Nz","executionInfo":{"status":"ok","timestamp":1697898350912,"user_tz":-480,"elapsed":371,"user":{"displayName":"Ruoheng Du","userId":"08748997774430241707"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["## bert ##\n","# load file\n","data = pd.read_excel('./data.xlsx')\n","sentences = data['review'].tolist()\n","\n","def txt_cut(s):\n","    res = [w for w in jieba.lcut(s) if w.strip()]\n","    return \" \".join(res)\n","\n","# 对文本进行分词\n","tokenized_text = []\n","for i in sentences:\n","    new = txt_cut(i).split(' ')\n","    tokenized_text.extend(new)\n","\n","# Load the tokenizer and model\n","tokenizer = BertTokenizer.from_pretrained(\"./bert-base-chinese\")\n","model = BertModel.from_pretrained(\"./bert-base-chinese\")\n","\n","# Define a list to store the word vectors\n","bert_vectors = []\n","\n","for word in tokenized_text:\n","\n","    inputs = tokenizer(word, return_tensors=\"pt\")\n","\n","    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n","\n","    outputs = model(**inputs)\n","\n","    word_vector = outputs.last_hidden_state[0].detach().numpy()\n","\n","    bert_vectors.append((word, word_vector))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VkwZD8uGkLka","executionInfo":{"status":"ok","timestamp":1697898385453,"user_tz":-480,"elapsed":8478,"user":{"displayName":"Ruoheng Du","userId":"08748997774430241707"}},"outputId":"02ca76ec-e2bc-4433-d0d1-e3a90918216f"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["Building prefix dict from the default dictionary ...\n","DEBUG:jieba:Building prefix dict from the default dictionary ...\n","Dumping model to file cache /tmp/jieba.cache\n","DEBUG:jieba:Dumping model to file cache /tmp/jieba.cache\n","Loading model cost 1.090 seconds.\n","DEBUG:jieba:Loading model cost 1.090 seconds.\n","Prefix dict has been built successfully.\n","DEBUG:jieba:Prefix dict has been built successfully.\n"]}]},{"cell_type":"code","source":["# for vector in enumerate(bert_vectors):\n","#     print(f\"word: {vector[1][0]}, shape: {vector[1][1].shape}, vector: {vector[1][1]}\")"],"metadata":{"id":"1t3iHYr5lRVY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from gensim.models import Word2Vec\n","import jieba\n","import numpy as np"],"metadata":{"id":"EDTP8nrNp0Oa","executionInfo":{"status":"ok","timestamp":1697898806589,"user_tz":-480,"elapsed":1235,"user":{"displayName":"Ruoheng Du","userId":"08748997774430241707"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["## word2vec ##\n","\n","# 初始化Word2Vec模型\n","model_w = Word2Vec(vector_size=100, window=5, min_count=1)\n","\n","# 构建词汇表\n","model_w.build_vocab([tokenized_text])\n","\n","# 训练模型\n","model_w.train([tokenized_text], total_examples=model_w.corpus_count, epochs=model_w.epochs)\n","\n","# 创建一个空的DataFrame来保存词汇和对应的词向量\n","word_vector_df = pd.DataFrame()\n","\n","for wd in model_w.wv.index_to_key:\n","    # 将词向量转化为Series，然后添加到DataFrame中\n","    word_vector_series = pd.Series([wd] + list(model_w.wv[wd]))\n","    word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bTWnkC2Xp0g2","executionInfo":{"status":"ok","timestamp":1697898808869,"user_tz":-480,"elapsed":4,"user":{"displayName":"Ruoheng Du","userId":"08748997774430241707"}},"outputId":"171fe5b6-1dc3-46b3-c5d7-85d537667326"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-36-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n"]}]},{"cell_type":"code","source":["new_word_vectors = []\n","\n","for word_vector in enumerate(bert_vectors):\n","    word_vector_b = np.mean(word_vector[1][1], axis=0)\n","    word_vector_b = word_vector_b.reshape(-1, 1)\n","\n","    ## word2vec\n","    word_vector_w = model_w.wv[word_vector[1][0]]\n","    word_vector_w = word_vector_w.reshape(-1, 1)\n","\n","    ## 新词向量\n","    new_word_vector = np.multiply(word_vector_b, word_vector_w.T)\n","    new_word_vectors.append((word, new_word_vector))"],"metadata":{"id":"5IcSN3UJp1AA","executionInfo":{"status":"ok","timestamp":1697898888812,"user_tz":-480,"elapsed":314,"user":{"displayName":"Ruoheng Du","userId":"08748997774430241707"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["# 指定保存文件路径\n","save_path = 'new_word_vectors.txt'\n","\n","# 保存单词和新词向量到文件\n","with open(save_path, 'w') as f:\n","    for word, word_vector in new_word_vectors:\n","        word_vector_str = ','.join(map(str, word_vector))\n","        line = f\"{word}: {word_vector_str}\\n\"\n","        f.write(line)"],"metadata":{"id":"q1MNdZZ3qQbH","executionInfo":{"status":"ok","timestamp":1697898947309,"user_tz":-480,"elapsed":29067,"user":{"displayName":"Ruoheng Du","userId":"08748997774430241707"}}},"execution_count":40,"outputs":[]}]}