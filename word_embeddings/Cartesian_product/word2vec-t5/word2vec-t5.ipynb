{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMBwFuqryf668OB0HNW1s+Q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pNv5nmcogvVT","executionInfo":{"status":"ok","timestamp":1697896651352,"user_tz":-480,"elapsed":12849,"user":{"displayName":"Ruoheng Du","userId":"08748997774430241707"}},"outputId":"053fd478-d68c-4493-c3e3-259382ec9f1f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n"]}]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zAQJB8CYhs2j","executionInfo":{"status":"ok","timestamp":1697896674880,"user_tz":-480,"elapsed":21665,"user":{"displayName":"Ruoheng Du","userId":"08748997774430241707"}},"outputId":"34ae589c-3f73-4230-f1c2-4804243b26bc"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers<0.15,>=0.14 (from transformers)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n","Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.1\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bpa4n58VCcPe","executionInfo":{"status":"ok","timestamp":1697896720813,"user_tz":-480,"elapsed":19105,"user":{"displayName":"Ruoheng Du","userId":"08748997774430241707"}},"outputId":"1b4cf3b4-bc65-41d5-de71-ccd730f3dbd2"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive/text_classification/dot/word2vec-t5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wROqqyOeCk3D","executionInfo":{"status":"ok","timestamp":1697896722605,"user_tz":-480,"elapsed":481,"user":{"displayName":"Ruoheng Du","userId":"08748997774430241707"}},"outputId":"89a1fe1c-17d4-4af4-ba0b-0ff26ed99a5d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/text_classification/dot/word2vec-t5\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from transformers import T5Tokenizer, T5Model\n","import torch\n","import jieba"],"metadata":{"id":"encHPIougB0k","executionInfo":{"status":"ok","timestamp":1697896732170,"user_tz":-480,"elapsed":7500,"user":{"displayName":"Ruoheng Du","userId":"08748997774430241707"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["## t5 ##\n","# Read excel file\n","data = pd.read_excel('./data.xlsx')\n","sentences = data['review'].tolist()\n","\n","def txt_cut(s):\n","    res = [w for w in jieba.lcut(s) if w.strip()]\n","    return \" \".join(res)\n","\n","# 对文本进行分词\n","tokenized_text = []\n","for i in sentences:\n","    new = txt_cut(i).split(' ')\n","    tokenized_text.extend(new)\n","\n","# Initialize T5 tokenizer and model\n","tokenizer = T5Tokenizer.from_pretrained('t5-base')\n","model = T5Model.from_pretrained('t5-base')\n","\n","# Create a list to store all the word vectors\n","all_vectors = []\n","\n","# Iterate through each row in the list\n","for word in tokenized_text:\n","\n","    # Encode the input\n","    inputs = tokenizer.encode_plus(word, return_tensors='pt', padding=True, truncation=True)\n","\n","    # Provide dummy decoder inputs\n","    inputs['decoder_input_ids'] = torch.tensor([[0]])\n","\n","    # Pass the input through the model and get the word vectors\n","    outputs = model(**inputs)\n","    last_hidden_states = outputs.last_hidden_state\n","\n","    # Append the tensor to all_vectors\n","    all_vectors.append((word, last_hidden_states))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tg1UsFeCM1F_","executionInfo":{"status":"ok","timestamp":1697896901755,"user_tz":-480,"elapsed":19254,"user":{"displayName":"Ruoheng Du","userId":"08748997774430241707"}},"outputId":"57f7659a-e3ba-4c66-b1bb-e0021c800ad9"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:240: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n","For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n","- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n","- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n","- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n","  warnings.warn(\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from gensim.models import Word2Vec\n","import jieba\n","import numpy as np"],"metadata":{"id":"VgbhIsXkQSpu","executionInfo":{"status":"ok","timestamp":1697896987901,"user_tz":-480,"elapsed":4,"user":{"displayName":"Ruoheng Du","userId":"08748997774430241707"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["## word2vec ##\n","\n","# 初始化Word2Vec模型\n","model_w = Word2Vec(vector_size=100, window=5, min_count=1)\n","\n","# 构建词汇表\n","model_w.build_vocab([tokenized_text])\n","\n","# 训练模型\n","model_w.train([tokenized_text], total_examples=model_w.corpus_count, epochs=model_w.epochs)\n","\n","# 创建一个空的DataFrame来保存词汇和对应的词向量\n","word_vector_df = pd.DataFrame()\n","\n","for wd in model_w.wv.index_to_key:\n","    # 将词向量转化为Series，然后添加到DataFrame中\n","    word_vector_series = pd.Series([wd] + list(model_w.wv[wd]))\n","    word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dUhaxowkRTSL","executionInfo":{"status":"ok","timestamp":1697896942029,"user_tz":-480,"elapsed":831,"user":{"displayName":"Ruoheng Du","userId":"08748997774430241707"}},"outputId":"740fca3e-277c-481d-e218-03e0eb201478"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n","<ipython-input-12-f084292095fa>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  word_vector_df = word_vector_df.append(word_vector_series, ignore_index=True)\n"]}]},{"cell_type":"code","source":["new_word_vectors = []\n","\n","for word_vector in enumerate(all_vectors):\n","    word_vector_g = word_vector[1][1].detach().numpy()\n","    word_vector_g = word_vector_g.reshape(-1, 1)\n","\n","    ## word2vec\n","    word_vector_w = model_w.wv[word_vector[1][0]]\n","    word_vector_w = word_vector_w.reshape(-1, 1)\n","\n","    ## 新词向量\n","    new_word_vector = np.multiply(word_vector_g, word_vector_w.T)\n","    new_word_vectors.append((word, new_word_vector))"],"metadata":{"id":"oVfO4Ep0RXo9","executionInfo":{"status":"ok","timestamp":1697896993101,"user_tz":-480,"elapsed":415,"user":{"displayName":"Ruoheng Du","userId":"08748997774430241707"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# 指定保存文件路径\n","save_path = 'new_word_vectors.txt'\n","\n","# 保存单词和新词向量到文件\n","with open(save_path, 'w') as f:\n","    for word, word_vector in new_word_vectors:\n","        word_vector_str = ','.join(map(str, word_vector))\n","        line = f\"{word}: {word_vector_str}\\n\"\n","        f.write(line)"],"metadata":{"id":"z1P7RhojjBjN","executionInfo":{"status":"ok","timestamp":1697897049205,"user_tz":-480,"elapsed":27374,"user":{"displayName":"Ruoheng Du","userId":"08748997774430241707"}}},"execution_count":18,"outputs":[]}]}